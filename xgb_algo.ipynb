{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# WSDM - KKBox's Churn Prediction Challenge\n",
    "\n",
    "Auteur: A. Carrere\n",
    "\n",
    "Date: 15 dÃ©cembre 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---IMPORTS OK---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/arnaud/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import gc; gc.enable()\n",
    "import xgboost as xgb\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "print(\"---IMPORTS OK---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---LOADING DATA---\n"
     ]
    }
   ],
   "source": [
    "#Data loading\n",
    "print(\"---LOADING DATA---\")\n",
    "train = pd.concat((pd.read_csv('../input/train.csv'), pd.read_csv('../input/train_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "test = pd.read_csv('../input/sample_submission_v2.csv')\n",
    "members = pd.read_csv('../input/members_v3.csv')\n",
    "transactions = pd.concat((pd.read_csv('../input/transactions.csv'), pd.read_csv('../input/transactions_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "transactions = transactions.sort_values(by=['transaction_date'], ascending=[False]).reset_index(drop=True)\n",
    "transactions = transactions.drop_duplicates(subset=['msno'], keep='first')\n",
    "#df_iter = pd.read_csv('../input/user_logs.csv', low_memory=False, iterator=True, chunksize=10000000)\n",
    "#user_logs_v2 = pd.read_csv('../input/user_logs_v2.csv',nrows=100000)\n",
    "print(\"---END---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FEATURE ENGINEERING---\n",
      "---END---\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering\n",
    "print(\"---FEATURE ENGINEERING---\")\n",
    "train['is_churn'] = train['is_churn'].astype(np.int8)\n",
    "\n",
    "members['city'] = members['city'].astype(np.int8)\n",
    "members['bd'] = members['bd'].astype(np.int16)\n",
    "members['registered_via'] = members['registered_via'].astype(np.int8)\n",
    "members['registration_init_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[:4]))\n",
    "members['registration_init_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['registration_init_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[-2:]))\n",
    "members['registration_init_year'] = members['registration_init_year'].astype(np.int16)\n",
    "members['registration_init_month'] = members['registration_init_month'].astype(np.int8)\n",
    "members['registration_init_date'] = members['registration_init_date'].astype(np.int8)\n",
    "gender = {'male':1, 'female':2}\n",
    "members['gender'] = members['gender'].map(gender)\n",
    "\n",
    "transactions['payment_method_id'] = transactions['payment_method_id'].astype(np.int8)\n",
    "transactions['payment_plan_days'] = transactions['payment_plan_days'].astype(np.int16)\n",
    "transactions['plan_list_price'] = transactions['plan_list_price'].astype(np.int16)\n",
    "transactions['actual_amount_paid'] = transactions['actual_amount_paid'].astype(np.int16)\n",
    "transactions['is_auto_renew'] = transactions['is_auto_renew'].astype(np.int8)\n",
    "transactions['is_cancel'] = transactions['is_cancel'].astype(np.int8)\n",
    "transactions['transaction_date_year'] = transactions['transaction_date'].apply(lambda x: int(str(x)[:4]))\n",
    "transactions['transaction_date_month'] = transactions['transaction_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "transactions['transaction_date_date'] = transactions['transaction_date'].apply(lambda x: int(str(x)[-2:]))\n",
    "transactions['transaction_date_year'] = transactions['transaction_date_year'].astype(np.int16)\n",
    "transactions['transaction_date_month'] = transactions['transaction_date_month'].astype(np.int8)\n",
    "transactions['transaction_date_date'] = transactions['transaction_date_date'].astype(np.int8)\n",
    "transactions['membership_expire_date_year'] = transactions['membership_expire_date'].apply(lambda x: int(str(x)[:4]))\n",
    "transactions['membership_expire_date_month'] = transactions['membership_expire_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "transactions['membership_expire_date_date'] = transactions['membership_expire_date'].apply(lambda x: int(str(x)[-2:]))\n",
    "transactions['membership_expire_date_year'] = transactions['membership_expire_date_year'].astype(np.int16)\n",
    "transactions['membership_expire_date_month'] = transactions['membership_expire_date_month'].astype(np.int8)\n",
    "transactions['membership_expire_date_date'] = transactions['membership_expire_date_date'].astype(np.int8)\n",
    "transactions['discount'] = transactions['plan_list_price'] - transactions['actual_amount_paid']\n",
    "transactions['amt_per_day'] = transactions['actual_amount_paid'] / transactions['payment_plan_days']\n",
    "transactions['is_discount'] = transactions.discount.apply(lambda x: 1 if x > 0 else 0)\n",
    "transactions['membership_days'] = pd.to_datetime(transactions['membership_expire_date']).subtract(pd.to_datetime(transactions['transaction_date'])).dt.days.astype(int)\n",
    "print(\"---END---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---USER_LOGS---\n"
     ]
    }
   ],
   "source": [
    "#Multiprocessing to model user_logs\n",
    "print(\"---USER_LOGS---\")\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.sort_values(by=['date'], ascending=[False])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop_duplicates(subset=['msno'], keep='first')\n",
    "    return df\n",
    "\n",
    "def transform_df2(df):\n",
    "    df = df.sort_values(by=['date'], ascending=[False])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop_duplicates(subset=['msno'], keep='first')\n",
    "    return df\n",
    "\n",
    "last_user_logs = []\n",
    "i = 0 #~400 Million Records - starting at the end but remove locally if needed\n",
    "for df in df_iter:\n",
    "    if i>35:\n",
    "        if len(df)>0:\n",
    "            #print(df.shape)\n",
    "            p = Pool(cpu_count())\n",
    "            df = p.map(transform_df, np.array_split(df, cpu_count()))   \n",
    "            df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "            df = transform_df2(df)\n",
    "            p.close(); p.join()\n",
    "            last_user_logs.append(df)\n",
    "            #print('...', df.shape)\n",
    "            df = []\n",
    "    i+=1\n",
    "\n",
    "last_user_logs.append(transform_df(user_logs_v2))\n",
    "last_user_logs = pd.concat(last_user_logs, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "last_user_logs = transform_df2(last_user_logs)\n",
    "print(\"---END---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---MERGING---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a057a671176f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---MERGING---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#We concatenate train+test to merge with transactions and members\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#Datadets merging\n",
    "print(\"---MERGING---\")\n",
    "#We concatenate train+test to merge with transactions and members\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "combined = pd.concat([train, test], axis = 0)\n",
    "combined = pd.merge(combined, members, how='left', on='msno')\n",
    "del members\n",
    "combined = pd.merge(combined, transactions, how='left', on='msno')\n",
    "del transactions\n",
    "#We separate train and split after merging\n",
    "train = combined[combined['is_train'] == 1]\n",
    "test = combined[combined['is_train'] == 0]\n",
    "train.drop(['is_train'], axis = 1, inplace = True)\n",
    "test.drop(['is_train'], axis = 1, inplace = True)\n",
    "del combined\n",
    "#Merging of train and test with the user logs\n",
    "#train = pd.merge(train, last_user_logs, how='left', on='msno')\n",
    "#test = pd.merge(test, last_user_logs, how='left', on='msno')\n",
    "#last_user_logs=[]\n",
    "print(\"---END---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Last feature engineering\n",
    "print(\"---CANCEL---\")\n",
    "train['autorenew_&_not_cancel'] = ((train.is_auto_renew == 1) == (train.is_cancel == 0)).astype(np.int8)\n",
    "test['autorenew_&_not_cancel'] = ((test.is_auto_renew == 1) == (test.is_cancel == 0)).astype(np.int8)\n",
    "train['notAutorenew_&_cancel'] = ((train.is_auto_renew == 0) == (train.is_cancel == 1)).astype(np.int8)\n",
    "test['notAutorenew_&_cancel'] = ((test.is_auto_renew == 0) == (test.is_cancel == 1)).astype(np.int8)\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "print(\"---END---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing with xgboost\n",
    "print(\"---TESTING---\")\n",
    "cols = [c for c in train.columns if c not in ['is_churn','msno']]\n",
    "\n",
    "def xgb_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'log_loss', metrics.log_loss(labels, preds)\n",
    "\n",
    "fold = 1\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.02, \n",
    "        'max_depth': 7,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'seed': 100,\n",
    "        'silent': True\n",
    "    }\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(train[cols], train['is_churn'], test_size=0.3, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 150,  watchlist, feval=xgb_score, maximize=False, verbose_eval=50, early_stopping_rounds=50) #use 1500\n",
    "    if i != 0:\n",
    "        pred1 += model.predict(xgb.DMatrix(test[cols]), ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred1 = model.predict(xgb.DMatrix(test[cols]), ntree_limit=model.best_ntree_limit)\n",
    "pred1 /= fold\n",
    "\n",
    "test['is_churn'] = pred1.clip(0.+1e-15, 1-1e-15)\n",
    "test[['msno','is_churn']].to_csv('../output/submission.csv', index=False)\n",
    "\n",
    "print(\"---DONE---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
